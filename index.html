<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-129673183-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-129673183-1');
</script>

  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <!-- <link rel="icon" type="image/png" href="images/icon.png"> -->
  <title>Shivanand Venkanna Sheshappanavar</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <!-- Bio and Image -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="80%" valign="middle">
              <p align="center">
                <name>Shivanand Venkanna Sheshappanavar</name>
              </p>
		  
	      <p>&nbsp;</p>
	       <p align="justify" style="color:red;">
	       <b><span color="red">
	       UNDER CONSTRUCTION... <a href="https://twitter.com/geometricintel" class="twitter-follow-button" data-show-count="false">Follow @GeometricIntel</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
	       </span></b>
	      </p>
              <p align="justify">
	       I am a PhD Graduate from the Dept. of Computer and Information Sciences at the University of Delaware. I did my doctoral research at the VIMS Laboratory under the guidance of <a href="https://www.eecis.udel.edu/~chandra/"> Dr. Chandra Kambhamettu</a>. I had completed my Masters in Computer Science at Syracuse University, New York (2018). Previously, I worked as an IT Consultant at Oracle India Private Limited (2012-2016). I also hold a Master's and a Bachelor's degree in Computer Science and Engineering from RVCE (2012) and MSRIT (2009), Bengaluru, respectively.
	      <p>
	      <p align="justify">
	       My primary research area is 3D Computer Vision (Mesh/Point Cloud Analysis, Geometric Deep Learning, Few-Shot/Incremental/Continual Learning, 3D Diffusion Models, and Neural Radiance Fields - NeRFs).
              </p>
	      <p align="justify" style="color:red;">
	       <b><span color="red">
	       I will join the Department of Electrical Engineering and Computer Science (EECS) at University of Wyoming as a tenure-track Assistant Professor from Fall 2023. I am actively looking for self-motivated students interested in 3D Computer Vision and Deep Learning. Please feel free to send me an email with your Resume/CV, along with a cover letter/statement of purpose and transcripts (unofficial) if you are interested!
	       </span></b>
	      </p>
	      <p align="justify"> <strong>
	        Recent News: </strong>
	        <ul>
		  <li> <i>May 2023:</i> <a href="https://youtu.be/t5Qaf87GDjQ">Featured in College of Engineering Class of 2023 Highlights</a></b>.
		  <li> <i>April 2023:</i> Recieved UD CIS <b>Distinguished Graduate Student Award</b>.
		  <li> <i> March 2023:</i> Defended PhD Dissertation!!!
		  <li> <i>March 2023:</i> Invited to review papers in IEEE/CVF International Conference on Computer Vision (ICCV) 2023.
		  <li> <i>Feb 2023: </i> Paper <a href="https://arxiv.org/pdf/2212.05140.pdf">Local Neighborhood Features for 3D Classification</a> accepted to <a href="https://sites.google.com/view/scia2023/home"><b>SCIA 2023</b> conference.</a>
<!-- 		  <li> <i>Feb 2023: </i> Invited to review a paper in journal IEEE Transactions on Circuits and Systems for Video Technology 2023. -->
		  <li> <i>Jan 2023: </i> Coming up <a href="http://vims.cis.udel.edu/3DGrocery100/"> 3DGrocery100 Project Page !!! </a>
<!-- 		  <li> <i>Dec 2022:</i> Invited to review a paper in journal Pattern Recognition 2023.
		  <li> <i>Nov 2022:</i> Invited to review papers in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2023.
		  <li> <i>July 2022:</i> Invited to review a paper in journal IEEE Robotics and Automation Letters (RAL) 2022. -->
		  <li> <i>April 2022:</i> Paper on <a href="https://ieeexplore.ieee.org/document/9874679">Neighborhood Views for Point Cloud Classification</a> accepted to <b>MIPR 2022</b>.
<!-- 		  <li> <i>March 2022:</i> Invited to review papers in European Conference on Computer Vision (ECCV) 2022.
		  <li> <i>February 2022:</i> Invited to review papers in IEEE International Conference on Pattern Recognition (ICPR) 2022.
		  <li> <i>December 2021:</i> Invited to review papers in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022. -->
		  <li> <i>August 2021:</i> Paper on <a href="https://openaccess.thecvf.com/content/ICCV2021W/DLGC/papers/Sheshappanavar_PatchAugment_Local_Neighborhood_Augmentation_in_Point_Cloud_Classification_ICCVW_2021_paper.pdf">PatchAugment</a> accepted at <b> ICCV 2021 Workshop </b>.
			<li> <i>May 2021:</i> Awarded <b>Best Teaching Assistant</b> (Dept. of CIS) for the academic year 2020-2021</b>.
	        </ul>
              </p>
	    </td>
<!-- 	    <td width="15%">
              <img src='images/self.pnh' width=100%>
            </td> -->
            <td width="22%">
              <img src="images/selfbg.png" width=100%>
            </td>
          </tr>
	  <tr>
            <td colspan="2">
              <p align=center margin=0px>
                <a href="mailto:ssheshap@udel.edu">Email</a> &nbsp/&nbsp
                <a href="data/ShivanandSheshappanavar_CV.pdf">CV</a> &nbsp/&nbsp
		<a href="data/Statement_of_Teaching_Philosophy.pdf">Teaching Philosophy</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=I1ajnioAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/sheshap">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/ssheshappanavar/"> LinkedIn </a>  &nbsp/&nbsp
		<a href="https://www.facebook.com/groups/PhDinUS"> PhDinUS (Facebook) </a>
             </p>
	     <p>&nbsp;</p>
	   </td>
	  </tr>
        </table>
	<div class = "row">
        <table width="100%" align="center" margin-top=100px>
            <tr>
              <td align="center" width="16%" style = "vertical-align: middle">
                <img src = "/images/UD.png" width="60%">
              </td>
		    
	      <td align="center" width="16%" style = "vertical-align: middle">
                <img src = "/images/syracuse.png" width="30%">
              </td>

              <td align="center" width="14%" style = "vertical-align: middle">
                <img src = "/images/oracle.png" width="50%">
              </td>

              <td align="center" width="14%" style = "vertical-align: middle">
                <img src = "/images/infineon.png" width="60%">
              </td>
            </tr>

            <tr>
                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">PhD, CS<br>University of Delaware<br>2018 - 2023</td>
		    
		<td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">MS, CS<br>Syracuse University<br>2016 - 2018</td>

                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">IT Consultant<br>Oracle<br>2012 - 2016</td>

                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">Research Intern<br>Infineon<br>2011 - 2012</td>

                <!-- <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">MTech<br>R.V. College of Engineering<br>2010 - 2012</td>

                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">BE<br>M.S.Ramaiah Institute of Technology<br>2005 - 2009</td> -->
          </tr>

          </table>
      </div>

        <!-- Research Interest -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td width="100%" valign="middle">
        <heading>Research</heading>
        <p align="justify">
          My research interests are to develop deep learning algorithms for 3D computer vision problems and create end-to-end solution pipelines. My long-term goal is to build a mobile-based assistant for the visually impaired to help them navigate the real world.
        </p>
      </td>
    </tr>
        </table>

        <!-- Publications-->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		
          <!-- Neighborhood Filling for Human Activity Recognition -->
          <tr>
            <td width="35%">
              <img src='images/NeighborFillingHAR.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="">
                  <papertitle>Neighborhood Filling for Human Activity Recognition</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Chandra Kambhamettu
		<br>
<!-- 		<em>22nd Scandinavian Conference In Image Analysis (SCIA), April 2023, Levi Ski Resort (Lapland), Finland. </em>
		<br> -->
		<a href="">[paper coming soon]</a> <a href="https://github.com/VimsLab/NeighborFillingHAR">[code]</a> <br>
		<p align="justify">The PST-Transformer model is one of the most influential recent neural architectures for human activity recognition in point cloud sequences. Although PST-Transformer has primarily surpassed the accuracy on the MSRAction3D dataset, the ball query limits its ability to capture the local neighborhood as ball querying repeats the anchor point in the absence of enough neighborhood points to query. In this paper, we address this drawback of ball querying in point cloud sequence modeling and propose ellipsoid querying for filling the neighborhood with unique points instead of redundant anchor points. Through our experiments, we demonstrate the superiority of the querying method in capturing local neighborhoods for hierarchical learning of features.</p>
            </td>
        </tr>
		
	<!-- 3DGrocery100 -->
          <tr>
            <td width="35%">
              <img src='images/main.png' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="http://vims.cis.udel.edu/3DGrocery100/">
                  <papertitle>3DGrocery100: a point cloud dataset</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Yufan Wang, Chandra Kambhamettu.
		<br>
		<a href="http://vims.cis.udel.edu/3DGrocery100/">[project page]</a> <a href="https://github.com/VimsLab/3DGrocery100">[code coming soon]</a> <br>
		<p align="justify">We introduce a large-scale grocery dataset called 3DGrocery100. It constitutes 100 classes, 10,755 RGB-D images, and 87,898 3D point cloud objects. We benchmark our dataset on six recent state-of-the-art 3D object classification models. 3DGrocery100 is the largest real-world 3D point cloud grocery dataset. </p>
            </td>
          </tr>	
		
	   <!-- Local Neighborhood Features for 3D Classification -->
          <tr>
            <td width="35%">
              <img src='images/PointNeXtLocals.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://arxiv.org/pdf/2212.05140.pdf">
                  <papertitle>Local Neighborhood Features for 3D Classification</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Chandra Kambhamettu
		<br>
		<em>22nd Scandinavian Conference In Image Analysis (SCIA), April 2023, Levi Ski Resort (Lapland), Finland. </em>
		<br>
		<a href="https://arxiv.org/pdf/2212.05140.pdf">[paper]</a> <a href="https://github.com/VimsLab/Local3DFeatures">[code]</a> <br>
		<p align="justify">With advances in deep learning model training strategies, the training of Point cloud classification methods is significantly improving. For example, PointNeXt, which adopts prominent training techniques and InvResNet layers into PointNet++, achieves over 7% improvement on the real-world ScanObjectNN dataset. However, most of these models use point coordinates features of neighborhood points mapped to higher dimensional space while ignoring the neighborhood point features computed before feeding to the network layers. In this paper, we revisit the PointNeXt model to study the usage and benefit of such neighborhood point features.</p>
            </td>
          </tr>
		
	  <!-- simpleview++ -->
          <tr>
            <td width="35%">
              <img src='images/simpleviewpp.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://ieeexplore.ieee.org/document/9874679">
                  <papertitle>SimpleView++: Neighborhood Views for Point Cloud Classification</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Chandra Kambhamettu
                <br>
                <em>IEEE 5th International Conference on Multimedia Information Processing and Retrieval (MIPR) 2022</em>
		<br>
		<a href="https://ieeexplore.ieee.org/document/9874679">[paper]</a> <a href="https://github.com/VimsLab/SimpleViewPlusPlus">[code]</a> <a href="https://youtu.be/lLoUiqqJPHg">[video]</a><br>
		<p align="justify">We propose the use of neighbor projections along with object projections to learn finer local structural information. SimpleView++ concatenates features from orthogonal perspective projections at object and neighbor levels with encoded features from the point cloud.</p>
            </td>
          </tr>

	  <!-- patch aug -->
          <tr>
            <td width="35%">
              <img src='images/patchaugment.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://openaccess.thecvf.com/content/ICCV2021W/DLGC/html/Sheshappanavar_PatchAugment_Local_Neighborhood_Augmentation_in_Point_Cloud_Classification_ICCVW_2021_paper.html">
                  <papertitle>PatchAugment: Local Neighborhood Augmentation in Point Cloud Classification</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Vinit Veerendraveer Singh, Chandra Kambhamettu
                <br>
                <em> IEEE/CVF International Conference on Computer Vision (ICCV) Workshops 2021</em>
		<br>
		<a href="https://openaccess.thecvf.com/content/ICCV2021W/DLGC/papers/Sheshappanavar_PatchAugment_Local_Neighborhood_Augmentation_in_Point_Cloud_Classification_ICCVW_2021_paper.pdf">[paper]</a> <a href="https://github.com/VimsLab/PatchAugment">[code]</a> <a href="https://youtu.be/YqP7UVhwdWQ">[video]</a> <br>
		<p align="justify">Different local neighborhoods on the object surface hold a different amount of geometric complexity. Applying the same data augmentation techniques at the object level is less effective in augmenting local neighborhoods with complex structures. This paper presents PatchAugment, a data augmentation framework to apply different augmentation techniques to the local neighborhoods.</p>
            </td>
          </tr>

	  <!-- dynamic scale -->
          <tr>
            <td width="35%">
              <img src='images/dynamicellipsoid.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://ieeexplore.ieee.org/document/9565556">
                  <papertitle>Dynamic local geometry capture in 3d point cloud classification</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Chandra Kambhamettu
                <br>
                <em>IEEE 4th International Conference on Multimedia Information Processing and Retrieval (MIPR) 2021</em>
		<br>
		<a href="https://ieeexplore.ieee.org/document/9565556">[paper]</a> <a href="https://github.com/VimsLab/DynamicScale">[code]</a> <a href="https://youtu.be/Ev44a02mwCg">[video]</a><br>
                <!-- <a href="https://syncedreview.com/2021/10/22/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-129/"><img src='images/synced.png' height=25px></a> &nbsp; &nbsp;
                <a href="https://papersread.ai/e/non-deep-networks/"><img src='images/podbean.png' height=25px></a> -->
		<p align="justify"> PointNet++ model uses ball querying for local geometry capture in its set abstraction layers. Several models based on single scale grouping of PointNet++ continue to use ball querying with a fixed-radius ball. However, ball lacks orientation and is ineffective in capturing complex or varying geometry proportions from different local neighborhoods on the object surface. We propose a novel technique of dynamically oriented and scaled ellipsoid based on unique local information to capture the local geometry better. We also propose ReducedPointNet++, a single set abstraction based single scale grouping model. </p>
            </td>
          </tr>
          <!-- dilated mesh -->
          <tr>
            <td width="35%">
              <img src='images/dmc.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://ieeexplore.ieee.org/document/9506311">
                  <papertitle>Mesh Classification with Dilated Mesh Convolutions</papertitle>
                </a>
                <br>
                Vinit Veerendraveer Singh, <strong>Shivanand Venkanna Sheshappanavar</strong>, Chandra Kambhamettu
                <br>
								  <em>IEEE International Conference on Image Processing (ICIP)</em> 2021
								<br>
                <!-- <em>NeuRIPS</em> 2020, <span style="color:brown;">Spotlight (Top 4% of submitted papers)</span>
		<br> -->
								<a href="https://ieeexplore.ieee.org/document/9506311">[paper]</a>
                <a href="https://github.com/VimsLab/DMC">[code]</a>
		<!-- <a href="https://drive.google.com/file/d/1lWA2WlJR4itJJrnHMRiZ87-z8akagkH4/view?usp=sharing">[slides]</a> -->

		<a href="https://youtu.be/Jdl71d3oMRE">[video]</a>
                <p align="justify"> In this paper, inspired by dilated convolutions for images, we proffer dilated convolutions for meshes. Our Dilated Mesh Convolution (DMC) unit inflates the kernels' receptive field without increasing the number of learnable parameters. We also propose a Stacked Dilated Mesh Convolution (SDMC) block by stacking DMC units. We accommodated SDMC in MeshNet to classify 3D meshes. </p>
            </td>
          </tr>

          <!-- meshnet++ -->
          <tr>
            <td width="35%">
              <img src='images/meshnet2.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://arxiv.org/abs/2007.11121">
                  <papertitle>MeshNet++: A Network with a Face</papertitle>
                </a>
                <br>
                Vinit Veerendraveer Singh, <strong>Shivanand Venkanna Sheshappanavar</strong>, Chandra Kambhamettu
                <br>
                <em>29th ACM International Conference on Multimedia (ACM MM Oral)</em> 2021
                <br>
								<a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475468">[paper]</a>
                <a href="https://github.com/VimsLab/MeshNet2">[code]</a>
								<a href="https://youtu.be/xcfnhrYqKac">[video]</a>
                <!-- <a href="data/packit_slides.pptx">[slides]</a> -->
                <p align="justify"> MeshNet is a pioneer in this direction. In this paper, we propose a novel neural network that is substantially deeper than its MeshNet predecessor. This increase in depth is achieved through our specialized convolution and pooling blocks that operate on mesh faces. Our network named MeshNet++ learns local structures at multiple scales and is also robust to shortcomings of mesh decimation. We evaluated it for the shape classification task on various data sets, and results significantly higher than state-of-the-art were observed.</p>
            </td>
          </tr>
	  <!-- ellipsoid -->
          <tr>
            <td width="35%">
              <img src='images/ellipsoid_querying.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://arxiv.org/abs/2106.05304">
                  <papertitle>A novel local geometry capture in pointnet++ for 3d classification</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Chandra Kambhamettu
                <br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em> 2020
		<br>
								<a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w16/Sheshappanavar_A_Novel_Local_Geometry_Capture_in_PointNet_for_3D_Classification_CVPRW_2020_paper.pdf">[paper]</a>
                <a href="https://github.com/VimsLab/EllipsoidQuery">[code]</a>
								<a href="https://youtu.be/OMZKTH85T8c">[video]</a>
		<!-- <a href="https://docs.google.com/presentation/d/1iYC5vDQPsb9nG9QCLwpm5TPL8i1F3sxu/edit?usp=sharing&ouid=116890615761823045471&rtpof=true&sd=true">[slides]</a> -->
		<!-- <a href="https://icml.cc/virtual/2021/poster/9099">[video]</a> -->
                <p align="justify">Few of the recent deep learning models for 3D point sets classification are dependent on how well the model captures the local geometric structures. PointNet++ model was able to extract the local region features from points by ball querying the local neighborhoods. However, ball querying is less effective in capturing local neighborhoods of high curvature surfaces or regions. In this paper, we demonstrate improvement in the 3D classification results by using ellipsoid querying around centroids, capturing more points in the local neighborhood. We extend the ellipsoid querying technique by orienting it in the direction of principal axes of the local neighborhood for better capture of the local geometry. </p>
            </td>
          </tr>

					<tr>
            <td width="35%">
              <img src='images/soil_moisture.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://arxiv.org/abs/2007.11121">
                  <papertitle>LSTM based Soil Moisture Prediction</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Chilukuri K. Mohan, David G. Chandler
                <br>
                <em>1st Northeast Regional Conference on Complex Systems (NERCCS)</em> 2018
                <br>
								<a href="https://github.com/sheshap/sheshap.github.io/blob/master/pdf/SoilMoisturePrediction_LSTM_NERCCS_2018.pdf">[paper]</a>
                <a href="https://github.com/sheshap/SoilMoisturePrediction">[code]</a>
								<!-- <a href="https://youtu.be/xcfnhrYqKac">[video]</a> -->
                <!-- <a href="data/packit_slides.pptx">[slides]</a> -->
                <p align="justify"> Soil moisture content is an important variable that has a considerable impact on agricultural processes and practical weather-related concerns such as flooding and drought. We address the problem of predicting soil moisture by applying recurrent neural networks that use Long Short-Term Memory (LSTM) models. The success of our approach is evaluated using a dataset obtained from ground-based sensor infrastructure networks. Feature reduction using a mutual information approach is shown to be more effective than feature extraction using principal component analysis.</p>
            </td>
          </tr>
        </table>

        <!-- Teaching -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="100%" valign="middle">
                <heading>Teaching</heading>
								<p>
									I have been the Instructor for the following course:
										<ul>
											<li>CISC210: Introduction to Systems Programming [Summer 2020]</li>
										</ul>
                  I have been the Lead Teaching Assistant for the following course:
                    <ul>
                      <li> CISC210: Introduction to Systems Programming at the University of Delaware[Fall 2022, Spring 2022, Spring 2021, Fall 2020, Spring 2020, Fall 2019, Spring 2019] </li>
                    </ul>
									I have been the Teaching Assistant for the following courses:
	                  <ul>
	                    <li> CISC220: Data Structures at the University of Delaware [Fall 2021] </li>
											<li> CISC101: Principles of Computing at the University of Delaware [Winter 2021] </li>
	                    <li> CISC662: Advanced Computer Architecture at the University of Delaware [Fall 2018]</li>
	                  </ul>
                </p>
		<!-- Some <a href="https:/related.html">related papers</a> to mine. -->
              </td>
            </tr>
        </table>

        <!-- Reference -->
        <p align="right"><a href="https://jonbarron.info/">[Web Cite]</a></p>
      </td>
    </tr>
  </table>

</body>

</html>
