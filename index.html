<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-129673183-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-129673183-1');
</script>

  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <!-- <link rel="icon" type="image/png" href="images/icon.png"> -->
  <title>Shivanand Venkanna Sheshappanavar</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <!-- Bio and Image -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr>
            <td width="80%" valign="middle">
              <p align="center">
                <name>Shivanand Venkanna Sheshappanavar</name>
              </p>
		  
	      <p>&nbsp;</p>
	      <p align="justify" style="color:red;">
	       <b><span color="red">
		 I actively seek self-motivated students interested in 3D Computer Vision and Deep Learning. If you are interested, please email me with your Resume/CV, cover letter/statement of purpose, and transcripts (unofficial)!
	       </span></b>
	      </p>
		    
              <p align="justify">
	       I graduated with a Ph.D. from the Dept. of Computer and Information Sciences at the University of Delaware. I did my doctoral research at the VIMS Laboratory under the guidance of <a href="https://www.eecis.udel.edu/~chandra/"> Dr. Chandra Kambhamettu</a>. I completed my Masters in Computer Science at Syracuse University, New York (2018). Previously, I worked as an IT Consultant at Oracle India Private Limited (2012-2016). I also hold a Master's and a Bachelor's degree in Computer Science and Engineering from RVCE (2012) and MSRIT (2009), Bengaluru, respectively.
	      <p>
	      <p align="justify">
	       My primary research area is 3D Computer Vision (Mesh/Point Cloud Analysis, Geometric Deep Learning, Few-Shot/Incremental/Continuous Learning, 3D Diffusion Models, 3D Gaussian Splatting, and Neural Radiation Fields), which has applications in Grocery recognition and Controlled-Environment Agriculture.
              </p>
	      
	      <p align="justify"> <strong>
	        Recent News: </strong>
	        <ul>
		  <li> <I>September 2024</i> Paper Accepted (Oral) at 23rd IEEE ICMLA, 2024 <b>EDADepth: Enhanced Data Augmentation for Monocular Depth Estimation</b>!
		  <li> <i>August 2024:</i> Invitation to serve as Reviewer (ICLR 2025).
		  <li> <i>August 2024:</i> Invited to serve as Program Committee (AAAI 2025).
	          <li> <I>August 2024:</i> Welcome to my first master's student Joana Owusu.
		  <li> <i>July 2024:</i> Invited to review papers for the Asian Conference on Computer Vision (ACCV) 2025.
	          <li> <I>May 2024:</i> Welcome to my first PhD student Michael Elgin.
		  <li> <I> May 2024: </i> Three years of Student Fellowship Funding secured for research on Controlled Environment Agriculture.
		  <li> <i>April 2024:</i> Invited to review papers for the European Conference on Computer Vision (ECCV) 2024.
		  <li> <i>December 2023:</i> Awarded School of Computing Spring 2024 Faculty Fellow (Single-PI, $30k)!!!.
		  <li> <i>October 2023:</i> One paper accepted in  <a href="https://3dvconf.github.io/2024/">3DV</a> Conference!!!.
		  <li> <i>August 2023:</i> Joined the Department of Electrical Engineering and Computer Science at the University of Wyoming as a Tenure-Track Assistant Professor
	        </ul>
              </p>
	    </td>
<!-- 	    <td width="15%">
              <img src='images/self.png' width=100%>
            </td> -->
            <td width="22%">
              <img src="images/selfbg.png" width=100%>
            </td>
          </tr>
	  <tr>
            <td colspan="2">
              <p align=center margin=0px>
                <a href="mailto:ssheshap@uwyo.edu">Email</a> &nbsp/&nbsp
                <a href="data/ShivanandSheshappanavar_CV.pdf">CV</a> &nbsp/&nbsp
		<a href="data/Statement_of_Teaching_Philosophy.pdf">Teaching Philosophy</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=I1ajnioAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/sheshap">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/ssheshappanavar/"> LinkedIn </a>  &nbsp/&nbsp
		<a href="https://www.facebook.com/groups/PhDinUS"> PhDinUS (Facebook) </a> &nbsp/&nbsp
		<a href="https://twitter.com/geometricintel" class="twitter-follow-button" data-show-count="false">Follow @GeometricIntel</a> &nbsp/&nbsp
		<a href="https://www.brains-explained.com/advice-for-applying-to-phd-programs/"> PhD Aspirants</a>
             </p>
	     <p>&nbsp;</p>
	   </td>
	  </tr>
        </table>
	<div class = "row">
        <table width="100%" align="center" margin-top=100px>
            <tr>
              <td align="center" width="16%" style = "vertical-align: middle">
                <img src = "/images/UD.png" width="60%">
              </td>
		    
	      <td align="center" width="16%" style = "vertical-align: middle">
                <img src = "/images/syracuse.png" width="30%">
              </td>

              <td align="center" width="14%" style = "vertical-align: middle">
                <img src = "/images/oracle.png" width="50%">
              </td>

              <td align="center" width="14%" style = "vertical-align: middle">
                <img src = "/images/infineon.png" width="60%">
              </td>
            </tr>

            <tr>
                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">PhD, CS<br>University of Delaware<br>2018 - 2023</td>
		    
		<td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">MS, CS<br>Syracuse University<br>2016 - 2018</td>

                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">IT Consultant<br>Oracle<br>2012 - 2016</td>

                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">Research Intern<br>Infineon<br>2011 - 2012</td>

                <!-- <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">MTech<br>R.V. College of Engineering<br>2010 - 2012</td>

                <td align="center" style = "vertical-align: middle; background-color: rgba(255, 255, 255, 1)">BE<br>M.S.Ramaiah Institute of Technology<br>2005 - 2009</td> -->
          </tr>

          </table>
      </div>


   <!-- Students -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	    <tr>
	      <td width="100%" valign="middle">
	        <heading>Students</heading>
	        <p align="justify">
		<a href="https://joan947.github.io/">Joana Konadu Owusu</a> (MS in CS, Aug 2024 - present) <br>
		<a href="http://michaelelgin.com/">Michael Elgin</a> (PhD in CS, May 2024 - present) <br>
	        </p>
	      </td>
	    </tr>
        </table>
	
        <!-- Research Interest -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td width="100%" valign="middle">
        <heading>Research</heading>
        <p align="justify">
          My research interests are to develop deep learning algorithms for 3D computer vision problems and create end-to-end solution pipelines. My long-term goal is to build a mobile-based assistant for the visually impaired to help them navigate the real world.
        </p>
      </td>
    </tr>
        </table>

        <!-- Publications-->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		 
          <tr>
            <td width="35%">
              <img src='images/EDADepth.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="">
                  <papertitle>EDADepth: Enhanced Data Augmentation for Monocular Depth Estimation </papertitle>
                </a>
                <br>
                <strong>Nischal Khanal</strong>,Shivanand Venkanna Sheshappanavar
		<br>
		<em>2024 23rd International Conference on Machine Learning and Applications (IEEE, 2024), December 2024, Miami, Florida, USA</em>
		<br>
		<a href="">[paper coming soon]</a> <a href="https://github.com/edadepthmde/EDADepth_ICMLA">[code]</a> <br>
		<p align="justify"> Due to their text-to-image synthesis feature, diffusion models have recently seen a rise in visual perception tasks, such as depth estimation. The lack of good-quality datasets makes extracting fine-grain semantic context challenging for the diffusion models. The semantic context with fewer details further worsens the process of creating effective text embeddings that will be used as input for diffusion models. In this paper, we propose a novel EDADepth, an Enhanced Data Augmentation method for Monocular Depth Estimation without using extra training data. We use Swin2SR, a super-resolution model, to enhance the quality of input images. We employ the BEiT pre-trained semantic segmentation model to better extract text embeddings (supported by our ablation study). Furthermore, we introduce the BLIP-2 tokenizer to generate tokens from these text embeddings. The novelty of our approach is the introduction of Swin2SR, BEiT model, and BLIP-2 tokenizer in the diffusion-based pipeline for monocular depth estimation. Our model achieves state-of-the-art results (SOTA) on the delta_3 metric on both NYUv2 and KITTI datasets. It also achieves results comparable to those of the SOTA models in the RMSE and REL metrics. Finally, we also show improvements in the visualization of the estimated depth compared to the SOTA diffusion-based monocular depth estimation models. We will make our code public upon acceptance of the paper.</p>
            </td>
        </tr>
		
	<!-- 3DGrocery100 -->
          <tr>
            <td width="35%">
              <img src='images/main.png' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="http://vims.cis.udel.edu/3DGrocery100/">
                  <papertitle>3DGrocery100: a point cloud dataset</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Tejas Anvekar, Shivanand_Kundargi, Yufan Wang, Chandra Kambhamettu.
		<br>
		<em> 2024 International Conference on 3D Vision (3DV) (IEEE, 2024), March 2024, Davos, Switzerland. </em>
		<br>
		<a href="https://arxiv.org/pdf/2402.07819.pdf">[paper]</a> <a href="http://vims.cis.udel.edu/3DGrocery100/">[project page]</a> <br>
		<p align="justify">We introduce a large-scale grocery dataset called 3DGrocery100. It constitutes 100 classes, 10,755 RGB-D images, and 87,898 3D point cloud objects. We benchmark our dataset on six recent state-of-the-art 3D object classification models. 3DGrocery100 is the largest real-world 3D point cloud grocery dataset. </p>
            </td>
          </tr>	
		
	   <!-- Local Neighborhood Features for 3D Classification -->
          <tr>
            <td width="35%">
              <img src='images/PointNeXtLocals.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://arxiv.org/pdf/2212.05140.pdf">
                  <papertitle>Local Neighborhood Features for 3D Classification</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Chandra Kambhamettu
		<br>
		<em>22nd Scandinavian Conference In Image Analysis (SCIA), April 2023, Levi Ski Resort (Lapland), Finland. </em>
		<br>
		<a href="https://arxiv.org/pdf/2212.05140.pdf">[paper]</a> <a href="https://github.com/VimsLab/Local3DFeatures">[code]</a> <br>
		<p align="justify">With advances in deep learning model training strategies, the training of Point cloud classification methods is significantly improving. For example, PointNeXt, which adopts prominent training techniques and InvResNet layers into PointNet++, achieves over 7% improvement on the real-world ScanObjectNN dataset. However, most of these models use point coordinates features of neighborhood points mapped to higher dimensional space while ignoring the neighborhood point features computed before feeding to the network layers. In this paper, we revisit the PointNeXt model to study the usage and benefit of such neighborhood point features.</p>
            </td>
          </tr>
		
	  <!-- simpleview++ -->
          <tr>
            <td width="35%">
              <img src='images/simpleviewpp.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://ieeexplore.ieee.org/document/9874679">
                  <papertitle>SimpleView++: Neighborhood Views for Point Cloud Classification</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Chandra Kambhamettu
                <br>
                <em>IEEE 5th International Conference on Multimedia Information Processing and Retrieval (MIPR) 2022</em>
		<br>
		<a href="https://ieeexplore.ieee.org/document/9874679">[paper]</a> <a href="https://github.com/VimsLab/SimpleViewPlusPlus">[code]</a> <a href="https://youtu.be/lLoUiqqJPHg">[video]</a><br>
		<p align="justify">We propose the use of neighbor projections along with object projections to learn finer local structural information. SimpleView++ concatenates features from orthogonal perspective projections at object and neighbor levels with encoded features from the point cloud.</p>
            </td>
          </tr>

	  <!-- patch aug -->
          <tr>
            <td width="35%">
              <img src='images/patchaugment.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://openaccess.thecvf.com/content/ICCV2021W/DLGC/html/Sheshappanavar_PatchAugment_Local_Neighborhood_Augmentation_in_Point_Cloud_Classification_ICCVW_2021_paper.html">
                  <papertitle>PatchAugment: Local Neighborhood Augmentation in Point Cloud Classification</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Vinit Veerendraveer Singh, Chandra Kambhamettu
                <br>
                <em> IEEE/CVF International Conference on Computer Vision (ICCV) Workshops 2021</em>
		<br>
		<a href="https://openaccess.thecvf.com/content/ICCV2021W/DLGC/papers/Sheshappanavar_PatchAugment_Local_Neighborhood_Augmentation_in_Point_Cloud_Classification_ICCVW_2021_paper.pdf">[paper]</a> <a href="https://github.com/VimsLab/PatchAugment">[code]</a> <a href="https://youtu.be/YqP7UVhwdWQ">[video]</a> <br>
		<p align="justify">Different local neighborhoods on the object surface hold a different amount of geometric complexity. Applying the same data augmentation techniques at the object level is less effective in augmenting local neighborhoods with complex structures. This paper presents PatchAugment, a data augmentation framework to apply different augmentation techniques to the local neighborhoods.</p>
            </td>
          </tr>

	  <!-- dynamic scale -->
          <tr>
            <td width="35%">
              <img src='images/dynamicellipsoid.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://ieeexplore.ieee.org/document/9565556">
                  <papertitle>Dynamic local geometry capture in 3d point cloud classification</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Chandra Kambhamettu
                <br>
                <em>IEEE 4th International Conference on Multimedia Information Processing and Retrieval (MIPR) 2021</em>
		<br>
		<a href="https://ieeexplore.ieee.org/document/9565556">[paper]</a> <a href="https://github.com/VimsLab/DynamicScale">[code]</a> <a href="https://youtu.be/Ev44a02mwCg">[video]</a><br>
                <!-- <a href="https://syncedreview.com/2021/10/22/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-129/"><img src='images/synced.png' height=25px></a> &nbsp; &nbsp;
                <a href="https://papersread.ai/e/non-deep-networks/"><img src='images/podbean.png' height=25px></a> -->
		<p align="justify"> PointNet++ model uses ball querying for local geometry capture in its set abstraction layers. Several models based on single scale grouping of PointNet++ continue to use ball querying with a fixed-radius ball. However, ball lacks orientation and is ineffective in capturing complex or varying geometry proportions from different local neighborhoods on the object surface. We propose a novel technique of dynamically oriented and scaled ellipsoid based on unique local information to capture the local geometry better. We also propose ReducedPointNet++, a single set abstraction based single scale grouping model. </p>
            </td>
          </tr>
          <!-- dilated mesh -->
          <tr>
            <td width="35%">
              <img src='images/dmc.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://ieeexplore.ieee.org/document/9506311">
                  <papertitle>Mesh Classification with Dilated Mesh Convolutions</papertitle>
                </a>
                <br>
                Vinit Veerendraveer Singh, <strong>Shivanand Venkanna Sheshappanavar</strong>, Chandra Kambhamettu
                <br>
								  <em>IEEE International Conference on Image Processing (ICIP)</em> 2021
								<br>
                <!-- <em>NeuRIPS</em> 2020, <span style="color:brown;">Spotlight (Top 4% of submitted papers)</span>
		<br> -->
								<a href="https://ieeexplore.ieee.org/document/9506311">[paper]</a>
                <a href="https://github.com/VimsLab/DMC">[code]</a>
		<!-- <a href="https://drive.google.com/file/d/1lWA2WlJR4itJJrnHMRiZ87-z8akagkH4/view?usp=sharing">[slides]</a> -->

		<a href="https://youtu.be/Jdl71d3oMRE">[video]</a>
                <p align="justify"> In this paper, inspired by dilated convolutions for images, we proffer dilated convolutions for meshes. Our Dilated Mesh Convolution (DMC) unit inflates the kernels' receptive field without increasing the number of learnable parameters. We also propose a Stacked Dilated Mesh Convolution (SDMC) block by stacking DMC units. We accommodated SDMC in MeshNet to classify 3D meshes. </p>
            </td>
          </tr>

          <!-- meshnet++ -->
          <tr>
            <td width="35%">
              <img src='images/meshnet2.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://arxiv.org/abs/2007.11121">
                  <papertitle>MeshNet++: A Network with a Face</papertitle>
                </a>
                <br>
                Vinit Veerendraveer Singh, <strong>Shivanand Venkanna Sheshappanavar</strong>, Chandra Kambhamettu
                <br>
                <em>29th ACM International Conference on Multimedia (ACM MM Oral)</em> 2021
                <br>
								<a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475468">[paper]</a>
                <a href="https://github.com/VimsLab/MeshNet2">[code]</a>
								<a href="https://youtu.be/xcfnhrYqKac">[video]</a>
                <!-- <a href="data/packit_slides.pptx">[slides]</a> -->
                <p align="justify"> MeshNet is a pioneer in this direction. In this paper, we propose a novel neural network that is substantially deeper than its MeshNet predecessor. This increase in depth is achieved through our specialized convolution and pooling blocks that operate on mesh faces. Our network named MeshNet++ learns local structures at multiple scales and is also robust to shortcomings of mesh decimation. We evaluated it for the shape classification task on various data sets, and results significantly higher than state-of-the-art were observed.</p>
            </td>
          </tr>
	  <!-- ellipsoid -->
          <tr>
            <td width="35%">
              <img src='images/ellipsoid_querying.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://arxiv.org/abs/2106.05304">
                  <papertitle>A novel local geometry capture in pointnet++ for 3d classification</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Chandra Kambhamettu
                <br>
                <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em> 2020
		<br>
								<a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w16/Sheshappanavar_A_Novel_Local_Geometry_Capture_in_PointNet_for_3D_Classification_CVPRW_2020_paper.pdf">[paper]</a>
                <a href="https://github.com/VimsLab/EllipsoidQuery">[code]</a>
								<a href="https://youtu.be/OMZKTH85T8c">[video]</a>
		<!-- <a href="https://docs.google.com/presentation/d/1iYC5vDQPsb9nG9QCLwpm5TPL8i1F3sxu/edit?usp=sharing&ouid=116890615761823045471&rtpof=true&sd=true">[slides]</a> -->
		<!-- <a href="https://icml.cc/virtual/2021/poster/9099">[video]</a> -->
                <p align="justify">Few of the recent deep learning models for 3D point sets classification are dependent on how well the model captures the local geometric structures. PointNet++ model was able to extract the local region features from points by ball querying the local neighborhoods. However, ball querying is less effective in capturing local neighborhoods of high curvature surfaces or regions. In this paper, we demonstrate improvement in the 3D classification results by using ellipsoid querying around centroids, capturing more points in the local neighborhood. We extend the ellipsoid querying technique by orienting it in the direction of principal axes of the local neighborhood for better capture of the local geometry. </p>
            </td>
          </tr>

					<tr>
            <td width="35%">
              <img src='images/soil_moisture.gif' width=100%>
            </td>
            <td valign="top" width="70%">
              <p>
                <a href="https://arxiv.org/abs/2007.11121">
                  <papertitle>LSTM based Soil Moisture Prediction</papertitle>
                </a>
                <br>
                <strong>Shivanand Venkanna Sheshappanavar</strong>, Chilukuri K. Mohan, David G. Chandler
                <br>
                <em>1st Northeast Regional Conference on Complex Systems (NERCCS)</em> 2018
                <br>
								<a href="https://github.com/sheshap/sheshap.github.io/blob/master/pdf/SoilMoisturePrediction_LSTM_NERCCS_2018.pdf">[paper]</a>
                <a href="https://github.com/sheshap/SoilMoisturePrediction">[code]</a>
								<!-- <a href="https://youtu.be/xcfnhrYqKac">[video]</a> -->
                <!-- <a href="data/packit_slides.pptx">[slides]</a> -->
                <p align="justify"> Soil moisture content is an important variable that has a considerable impact on agricultural processes and practical weather-related concerns such as flooding and drought. We address the problem of predicting soil moisture by applying recurrent neural networks that use Long Short-Term Memory (LSTM) models. The success of our approach is evaluated using a dataset obtained from ground-based sensor infrastructure networks. Feature reduction using a mutual information approach is shown to be more effective than feature extraction using principal component analysis.</p>
            </td>
          </tr>
        </table>

        <!-- Teaching -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="100%" valign="middle">
                <heading>Teaching</heading>
								<p>
									I have been the Instructor for the following courses at the University of Wyoming:
										<ul>
											<li> EE 5885/COSC 5010: Advances in 3D Computer Vision [Spring 2024]</li>
											<li>EE/COSC 2150: Computer Organization [Fall 2023]</li>
										</ul>
									I have been the Instructor for the below course at the University of Delaware:
										<ul>
											<li>CISC210: Introduction to Systems Programming [Summer 2020]</li>
										</ul>
                  I have been the Lead Teaching Assistant for the following course:
                    <ul>
                      <li> CISC210: Introduction to Systems Programming at the University of Delaware[Fall 2022, Spring 2022, Spring 2021, Fall 2020, Spring 2020, Fall 2019, Spring 2019] </li>
                    </ul>
									I have been the Teaching Assistant for the following courses:
	                  <ul>
	                    <li> CISC220: Data Structures at the University of Delaware [Fall 2021] </li>
											<li> CISC101: Principles of Computing at the University of Delaware [Winter 2021] </li>
	                    <li> CISC662: Advanced Computer Architecture at the University of Delaware [Fall 2018]</li>
	                  </ul>
                </p>
		<!-- Some <a href="https:/related.html">related papers</a> to mine. -->
              </td>
            </tr>
        </table>

        <!-- Reference -->
        <p align="right"><a href="https://jonbarron.info/">[Web Cite]</a></p>
      </td>
    </tr>
  </table>
<!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=dwLb98e9AbmFEevS3BoXkPs2XsruHEpsHIDn9lpN6Zs&cl=ffffff&w=a"></script> -->
	<a href="https://clustrmaps.com/site/1byya"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=dwLb98e9AbmFEevS3BoXkPs2XsruHEpsHIDn9lpN6Zs&cl=ffffff" /></a>
</body>

</html>
